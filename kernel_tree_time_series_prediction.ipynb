{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel time series prediction\n",
    "\n",
    "This notebook generates reference results on all tree data sets using _Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces_ ([Paaßen, Göpfert, and Hammer, 2018](https://arxiv.org/abs/1704.06498)). This method performs a prediction in kernel space as follows. Let $\\{(x_i, y_i)\\}_{i \\in \\{1, \\ldots, m\\}}$ be the training data where $y_i$ is the true successor of $x_i$. Then, the prediction $\\phi(y)$ in kernel space for the input tree $x$ is given as\n",
    "\n",
    "$$\\phi(y) = \\phi(x) + \\sum_i \\gamma_i \\cdot [ \\phi(y_i) - \\phi(x_i) ]$$\n",
    "\n",
    "where $\\vec \\gamma = \\big( K + \\sigma^2 \\cdot I \\big)^{-1} \\cdot \\vec k(x)$ are the coefficients computed by Gaussian process/kernel prediction, where $K$ is the kernel matrix between all training data and where $\\vec k(x)$ is the vector of kernel values from $x$ to all training trees. The kernel we use here is $k(x, y) = \\exp\\big(-\\frac{1}{2 \\psi^2} \\cdot d(x, y)^2 \\big)$, where $d$ is the tree edit distance and $\\psi$ is a hyper-parameter called bandwidth. This is the suggested kernel of ([Paaßen, Göpfert, and Hammer, 2018](https://arxiv.org/abs/1704.06498)).\n",
    "\n",
    "To map back from kernel space to a tree we employ the scheme recommended by the authors in ([Paaßen et al., 2018](https://jedm.educationaldatamining.org/index.php/JEDM/article/view/158)). In particular, we greedily apply edits $\\delta$ to $x$ that move towards training data trees $y_i$ with positive coefficients $\\gamma_i$ or towards training data trees $x_i$ with negative coefficients $\\gamma_i$ and which reduce the loss\n",
    "\n",
    "$$\\ell(\\delta) = d(x, \\delta(x))^2 + \\sum_i \\gamma_i [ d(\\delta(x), y_i)^2 - d(\\delta(x), x_i)^2) ]$$\n",
    "\n",
    "until no edit $\\delta$ is found anymore which reduces the loss.\n",
    "\n",
    "For even more details, please refer to the source code at `kernel_time_series_prediction.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Formulae and Peano Addition\n",
    "\n",
    "Refer to `boolean_formulae.py` and `peano_additon.py` for details on the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " --- task boolean --- \n",
      "\n",
      "repeat 1 of 5\n",
      "took 0.137753 seconds to train\n",
      "took 0.470501 seconds to predict\n",
      "RMSE: 2.41091 versus baseline RMSE 1.45774\n",
      "repeat 2 of 5\n",
      "took 0.129635 seconds to train\n",
      "took 0.469569 seconds to predict\n",
      "RMSE: 2.43812 versus baseline RMSE 1.61589\n",
      "repeat 3 of 5\n",
      "took 0.135248 seconds to train\n",
      "took 0.419243 seconds to predict\n",
      "RMSE: 2.46306 versus baseline RMSE 1.52753\n",
      "repeat 4 of 5\n",
      "took 0.130834 seconds to train\n",
      "took 0.215008 seconds to predict\n",
      "RMSE: 2 versus baseline RMSE 1.7097\n",
      "repeat 5 of 5\n",
      "took 0.131168 seconds to train\n",
      "took 0.382734 seconds to predict\n",
      "RMSE: 2.65684 versus baseline RMSE 1.59041\n",
      "\n",
      "\n",
      " --- task peano --- \n",
      "\n",
      "repeat 1 of 5\n",
      "took 3.70749 seconds to train\n",
      "took 58.3135 seconds to predict\n",
      "RMSE: 5.38069 versus baseline RMSE 3\n",
      "repeat 2 of 5\n",
      "took 4.74174 seconds to train\n",
      "took 65.4441 seconds to predict\n",
      "RMSE: 3.96863 versus baseline RMSE 2.79322\n",
      "repeat 3 of 5\n",
      "took 3.83915 seconds to train\n",
      "took 61.2994 seconds to predict\n",
      "RMSE: 4.89415 versus baseline RMSE 3.44944\n",
      "repeat 4 of 5\n",
      "took 4.83539 seconds to train\n",
      "took 60.4223 seconds to predict\n",
      "RMSE: 3.52332 versus baseline RMSE 2.77302\n",
      "repeat 5 of 5\n",
      "took 5.58519 seconds to train\n",
      "took 88.7766 seconds to predict\n",
      "RMSE: 4.94673 versus baseline RMSE 3.19398\n"
     ]
    }
   ],
   "source": [
    "# evaluate kernel tree time series prediction on both tasks in five repeats\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import python_ast_utils\n",
    "import edist.tree_utils as tu\n",
    "import edist.tree_edits as te\n",
    "import edist.ted as ted\n",
    "import boolean_formulae\n",
    "import peano_addition\n",
    "from kernel_time_series_prediction import KernelTreePredictor\n",
    "\n",
    "R = 5\n",
    "# the number of time series we generate for training\n",
    "M = 100\n",
    "# the number of time series for testing\n",
    "N_test = 10\n",
    "\n",
    "# model hyper parameters\n",
    "psi   = None\n",
    "sigma = 1E-3\n",
    "\n",
    "tasks = ['boolean', 'peano']\n",
    "\n",
    "errors = np.zeros((len(tasks), R))\n",
    "baseline_errors = np.zeros((len(tasks), R))\n",
    "times  = np.zeros((len(tasks), R))\n",
    "prediction_times  = np.zeros((len(tasks), R))\n",
    "\n",
    "# iterate over all tasks\n",
    "for task_idx in range(len(tasks)):\n",
    "    task = tasks[task_idx]\n",
    "    print('\\n\\n --- task %s --- \\n' % task)\n",
    "    if task == 'boolean':\n",
    "        sampling_fun = boolean_formulae.generate_time_series\n",
    "    else:\n",
    "        sampling_fun = peano_addition.generate_time_series\n",
    "\n",
    "    # do repeats\n",
    "    for r in range(R):\n",
    "        print('repeat %d of %d' % (r+1, R))\n",
    "        # sample random training data\n",
    "        training_data = []\n",
    "        for i in range(M):\n",
    "            training_data.append(sampling_fun())\n",
    "        # fit model\n",
    "        start = time.time()\n",
    "        model = KernelTreePredictor(psi = psi, sigma = sigma)\n",
    "        model.fit(training_data)\n",
    "        times[task_idx, r] = time.time() - start\n",
    "        print('took %g seconds to train' % times[task_idx, r])\n",
    "        # evaluate it on the test data\n",
    "        rmse = 0.\n",
    "        baseline_rmse = 0.\n",
    "        m = 0\n",
    "        for i in range(N_test):\n",
    "            # sample test time series\n",
    "            time_series = sampling_fun()\n",
    "            for t in range(len(time_series)-1):\n",
    "                nodes, adj = time_series[t][0], time_series[t][1]\n",
    "                # predict next tree\n",
    "                start = time.time()\n",
    "                _, nodes_pred, adj_pred = model.predict(nodes, adj)\n",
    "                prediction_times[task_idx, r] += time.time() - start\n",
    "                # compare to actual next tree\n",
    "                nodes_act, adj_act = time_series[t+1][0], time_series[t+1][1]\n",
    "                d = ted.ted(nodes, adj, nodes_act, adj_act)\n",
    "                baseline_rmse += d * d\n",
    "                if nodes_pred != nodes_act or adj_pred != adj_act:\n",
    "                    d = ted.ted(nodes_pred, adj_pred, nodes_act, adj_act)\n",
    "                    rmse += d * d\n",
    "            m += len(time_series)\n",
    "        rmse = np.sqrt(rmse / m)\n",
    "        baseline_rmse = np.sqrt(baseline_rmse / m)\n",
    "        prediction_times[task_idx, r] /= m\n",
    "        print('took %g seconds to predict' % prediction_times[task_idx, r])\n",
    "        errors[task_idx, r] = rmse\n",
    "        baseline_errors[task_idx, r] = baseline_rmse\n",
    "        print('RMSE: %g versus baseline RMSE %g' % (rmse, baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the experimental results\n",
    "np.savetxt('results/kernel_synthetic_times.csv', times.T, delimiter='\\t', header='\\t'.join(tasks), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_synthetic_predict_times.csv', prediction_times.T, delimiter='\\t', header='\\t'.join(tasks), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_synthetic_rmses.csv', errors.T, delimiter='\\t', header=('\\t'.join(tasks)), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_synthetic_baseline_rmses.csv', baseline_errors.T, delimiter='\\t', header=('\\t'.join(tasks)), fmt='%g', comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " --- task fun --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14]\n",
      "test_idxs: [6, 9, 12]\n",
      "took 0.1365 seconds to train\n",
      "took 0.338039 seconds to predict\n",
      "RMSE: 10.7319 versus baseline RMSE 6.245\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [0, 1, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14]\n",
      "test_idxs: [2, 5, 7]\n",
      "took 0.141758 seconds to train\n",
      "took 0.437477 seconds to predict\n",
      "RMSE: 8.08775 versus baseline RMSE 5.97052\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13]\n",
      "test_idxs: [3, 8, 14]\n",
      "took 0.141499 seconds to train\n",
      "took 0.53131 seconds to predict\n",
      "RMSE: 11.7724 versus baseline RMSE 7.74597\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 14]\n",
      "test_idxs: [4, 11, 13]\n",
      "took 0.148223 seconds to train\n",
      "took 0.421412 seconds to predict\n",
      "RMSE: 9.56794 versus baseline RMSE 7.55585\n",
      "\n",
      "---fold 5 of 5 ---\n",
      "train_idxs: [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]\n",
      "test_idxs: [0, 1, 10]\n",
      "took 0.145582 seconds to train\n",
      "took 0.452888 seconds to predict\n",
      "RMSE: 8.28471 versus baseline RMSE 7.73422\n",
      "\n",
      "\n",
      " --- task plt --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [0, 1, 2, 4, 6, 7, 8, 9, 11, 12, 13, 14]\n",
      "test_idxs: [3, 5, 10]\n",
      "took 0.131368 seconds to train\n",
      "took 2.3368 seconds to predict\n",
      "RMSE: 11.1181 versus baseline RMSE 5.05525\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14]\n",
      "test_idxs: [0, 6, 7]\n",
      "took 0.136827 seconds to train\n",
      "took 1.27528 seconds to predict\n",
      "RMSE: 4.47574 versus baseline RMSE 2.52727\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "test_idxs: [11, 13, 14]\n",
      "took 0.138659 seconds to train\n",
      "took 1.33508 seconds to predict\n",
      "RMSE: 7.84219 versus baseline RMSE 2.66458\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14]\n",
      "test_idxs: [1, 4, 8]\n",
      "took 0.133835 seconds to train\n",
      "took 1.17972 seconds to predict\n",
      "RMSE: 4.90516 versus baseline RMSE 2.90245\n",
      "\n",
      "---fold 5 of 5 ---\n",
      "train_idxs: [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14]\n",
      "test_idxs: [2, 9, 12]\n",
      "took 0.134156 seconds to train\n",
      "took 1.39508 seconds to predict\n",
      "RMSE: 4.71593 versus baseline RMSE 4.53872\n",
      "\n",
      "\n",
      " --- task grad --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
      "test_idxs: [1, 2, 11]\n",
      "took 0.138149 seconds to train\n",
      "took 0.816669 seconds to predict\n",
      "RMSE: 6.71751 versus baseline RMSE 8.9861\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 7, 8, 11, 12, 13, 14]\n",
      "test_idxs: [6, 9, 10]\n",
      "took 0.170676 seconds to train\n",
      "took 0.764256 seconds to predict\n",
      "RMSE: 8.55631 versus baseline RMSE 4.46625\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "test_idxs: [0, 3, 14]\n",
      "took 0.139529 seconds to train\n",
      "took 0.86557 seconds to predict\n",
      "RMSE: 7.01997 versus baseline RMSE 6.11555\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 14]\n",
      "test_idxs: [4, 5, 12]\n",
      "took 0.143609 seconds to train\n",
      "took 0.75202 seconds to predict\n",
      "RMSE: 11.3998 versus baseline RMSE 5.35554\n",
      "\n",
      "---fold 5 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14]\n",
      "test_idxs: [7, 8, 13]\n",
      "took 0.1362 seconds to train\n",
      "took 0.815971 seconds to predict\n",
      "RMSE: 9.81495 versus baseline RMSE 5.1251\n",
      "\n",
      "\n",
      " --- task desc --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 13, 14]\n",
      "test_idxs: [8, 9, 12]\n",
      "took 0.537998 seconds to train\n",
      "took 8.06018 seconds to predict\n",
      "RMSE: 8.42303 versus baseline RMSE 2.9824\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13]\n",
      "test_idxs: [1, 6, 14]\n",
      "took 0.43995 seconds to train\n",
      "took 11.6276 seconds to predict\n",
      "RMSE: 17.4685 versus baseline RMSE 3.68681\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14]\n",
      "test_idxs: [0, 7, 10]\n",
      "took 0.335314 seconds to train\n",
      "took 12.9728 seconds to predict\n",
      "RMSE: 10.3385 versus baseline RMSE 3.96135\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14]\n",
      "test_idxs: [2, 11, 13]\n",
      "took 0.433435 seconds to train\n",
      "took 12.5903 seconds to predict\n",
      "RMSE: 16.27 versus baseline RMSE 3.65474\n",
      "\n",
      "---fold 5 of 5 ---\n",
      "train_idxs: [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "test_idxs: [3, 4, 5]\n",
      "took 0.434208 seconds to train\n",
      "took 14.0512 seconds to predict\n",
      "RMSE: 17.3564 versus baseline RMSE 4.85464\n",
      "\n",
      "\n",
      " --- task fin --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 13, 14]\n",
      "test_idxs: [4, 11, 12]\n",
      "took 0.136183 seconds to train\n",
      "took 0.0860003 seconds to predict\n",
      "RMSE: 1.27098 versus baseline RMSE 1.30089\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13]\n",
      "test_idxs: [1, 6, 14]\n",
      "took 0.140488 seconds to train\n",
      "took 0.0828667 seconds to predict\n",
      "RMSE: 1.10195 versus baseline RMSE 1.13389\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14]\n",
      "test_idxs: [0, 7, 10]\n",
      "took 0.141212 seconds to train\n",
      "took 0.0927297 seconds to predict\n",
      "RMSE: 1.08711 versus baseline RMSE 1.12815\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]\n",
      "test_idxs: [2, 3, 13]\n",
      "took 0.142505 seconds to train\n",
      "took 0.100828 seconds to predict\n",
      "RMSE: 2.30612 versus baseline RMSE 2.0226\n",
      "\n",
      "---fold 5 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14]\n",
      "test_idxs: [5, 8, 9]\n",
      "took 0.141953 seconds to train\n",
      "took 0.102339 seconds to predict\n",
      "RMSE: 0.852803 versus baseline RMSE 0.852803\n",
      "\n",
      "\n",
      " --- task pysort --- \n",
      "\n",
      "\n",
      "---fold 1 of 5 ---\n",
      "train_idxs: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 26, 28]\n",
      "test_idxs: [0, 4, 20, 21, 23, 27]\n",
      "took 2.44704 seconds to train\n",
      "took 144.005 seconds to predict\n",
      "RMSE: 26.686 versus baseline RMSE 13.2573\n",
      "\n",
      "---fold 2 of 5 ---\n",
      "train_idxs: [0, 1, 2, 4, 5, 7, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "test_idxs: [3, 6, 8, 10, 14, 15]\n",
      "took 2.34584 seconds to train\n",
      "took 143.26 seconds to predict\n",
      "RMSE: 25.1974 versus baseline RMSE 12.2141\n",
      "\n",
      "---fold 3 of 5 ---\n",
      "train_idxs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 27, 28]\n",
      "test_idxs: [9, 16, 18, 19, 25, 26]\n",
      "took 2.14207 seconds to train\n",
      "took 156.815 seconds to predict\n",
      "RMSE: 23.9147 versus baseline RMSE 13.1876\n",
      "\n",
      "---fold 4 of 5 ---\n",
      "train_idxs: [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27]\n",
      "test_idxs: [2, 7, 11, 17, 22, 28]\n",
      "took 2.51078 seconds to train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6455cb707a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# predict next tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mcrossval_prediction_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# compare to actual next tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GIT/graph-transformers/kernel_time_series_prediction.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, nodes, adj)\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                         \u001b[0mnext_d2_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                         \u001b[0mnext_d2_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_d2_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate kernel tree time series prediction on all tasks in crossvalidation\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import python_ast_utils\n",
    "import edist.tree_utils as tu\n",
    "import edist.tree_edits as te\n",
    "import edist.ted as ted\n",
    "from kernel_time_series_prediction import KernelTreePredictor\n",
    "\n",
    "psi   = None\n",
    "sigma = 1E-3\n",
    "num_folds     = 5\n",
    "\n",
    "tasks = python_ast_utils._tasks + ['pysort']\n",
    "\n",
    "crossval_errors = np.zeros((len(tasks), num_folds))\n",
    "baseline_errors = np.zeros((len(tasks), num_folds))\n",
    "crossval_times  = np.zeros((len(tasks), num_folds))\n",
    "crossval_prediction_times  = np.zeros((len(tasks), num_folds))\n",
    "\n",
    "# iterate over all tasks\n",
    "for task_idx in range(len(tasks)):\n",
    "    task = tasks[task_idx]\n",
    "    print('\\n\\n --- task %s --- \\n' % task)\n",
    "    if task == 'pysort':\n",
    "        data = python_ast_utils.load_pysort()\n",
    "    else:\n",
    "        data = python_ast_utils.load_task_cleaned(task)\n",
    "\n",
    "    # load the folds\n",
    "    with open('results/%s_folds.json' % task) as folds_file:\n",
    "        folds = json.load(folds_file)\n",
    "\n",
    "    if len(folds) != num_folds:\n",
    "        raise ValueError('Expected %d folds but got %d from file %s' % (num_folds, len(folds), 'results/%s_folds.json' % task))\n",
    "\n",
    "    # iterate over all folds\n",
    "    for f in range(num_folds):\n",
    "        train_data_idxs = folds[f][0]\n",
    "        test_data_idxs  = folds[f][1]\n",
    "        print('\\n---fold %d of %d ---' % (f+1, num_folds))\n",
    "        print('train_idxs: %s' % str(train_data_idxs))\n",
    "        print('test_idxs: %s' % str(test_data_idxs))\n",
    "        # get training and test data for the current fold\n",
    "        train_data = []\n",
    "        for i in train_data_idxs:\n",
    "            train_data.append(data[i])\n",
    "        test_data = []\n",
    "        for i in test_data_idxs:\n",
    "            test_data.append(data[i])\n",
    "        # train the kernel regression model\n",
    "        start = time.time()\n",
    "        model = KernelTreePredictor(psi = psi, sigma = sigma)\n",
    "        model.fit(train_data)\n",
    "        crossval_times[task_idx, f] = time.time() - start\n",
    "        print('took %g seconds to train' % crossval_times[task_idx, f])\n",
    "        # evaluate it on the test data\n",
    "        rmse = 0.\n",
    "        baseline_rmse = 0.\n",
    "        m = 0\n",
    "        for i in range(len(test_data)):\n",
    "            time_series = test_data[i]\n",
    "            for t in range(len(time_series)):\n",
    "                nodes, adj = time_series[t][0], time_series[t][1]\n",
    "                # predict next tree\n",
    "                start = time.time()\n",
    "                _, nodes_pred, adj_pred = model.predict(nodes, adj)\n",
    "                crossval_prediction_times[task_idx, f] += time.time() - start\n",
    "                # compare to actual next tree\n",
    "                if t < len(time_series)-1:\n",
    "                    nodes_act, adj_act = time_series[t+1][0], time_series[t+1][1]\n",
    "                else:\n",
    "                    nodes_act, adj_act = nodes, adj\n",
    "                d = ted.ted(nodes, adj, nodes_act, adj_act)\n",
    "                baseline_rmse += d * d\n",
    "                if nodes_pred != nodes_act or adj_pred != adj_act:\n",
    "                    d = ted.ted(nodes_pred, adj_pred, nodes_act, adj_act)\n",
    "                    rmse += d * d\n",
    "            m += len(time_series)\n",
    "        rmse = np.sqrt(rmse / m)\n",
    "        baseline_rmse = np.sqrt(baseline_rmse / m)\n",
    "        crossval_prediction_times[task_idx, f] /= m\n",
    "        print('took %g seconds to predict' % crossval_prediction_times[task_idx, f])\n",
    "        crossval_errors[task_idx, f] = rmse\n",
    "        baseline_errors[task_idx, f] = baseline_rmse\n",
    "        print('RMSE: %g versus baseline RMSE %g' % (rmse, baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the experimental results\n",
    "\n",
    "np.savetxt('results/kernel_crossval_times.csv', crossval_times.T, delimiter='\\t', header='\\t'.join(tasks), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_crossval_predict_times.csv', crossval_prediction_times.T, delimiter='\\t', header='\\t'.join(tasks), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_crossval_rmses.csv', crossval_errors.T, delimiter='\\t', header=('\\t'.join(tasks)), fmt='%g', comments = '')\n",
    "np.savetxt('results/kernel_crossval_baseline_rmses.csv', baseline_errors.T, delimiter='\\t', header=('\\t'.join(tasks)), fmt='%g', comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
