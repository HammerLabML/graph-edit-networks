{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Dynamical Systems\n",
    "\n",
    "This notebooks contains the experiments to evaluate graph edit networks on simple graph dynamical systems, namely the edit cycles, degree rules, and game of life datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "import pytorch_graph_edit_networks as gen\n",
    "import baseline_models\n",
    "import os\n",
    "import time\n",
    "import hep_th\n",
    "\n",
    "# model hyperparameters\n",
    "num_layers = 2\n",
    "dim_hid = 64\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate  = 1E-3\n",
    "weight_decay   = 1E-5\n",
    "loss_threshold = 1E-3\n",
    "max_epochs     = 50000\n",
    "print_step     = 1000\n",
    "\n",
    "R = 5        # number of repetitions for each experiment\n",
    "N_test = 10  # number of test time series we use to evaluate learning afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SETUP FUNCTIONS\n",
    "def setup_vgae(dim_in, nonlin):\n",
    "    return baseline_models.VGAE(num_layers=num_layers,\n",
    "                                dim_in=dim_in,\n",
    "                                dim_hid=dim_hid,\n",
    "                                beta=1E-3,\n",
    "                                sigma_scaling=1E-3,\n",
    "                                nonlin=nonlin)\n",
    "\n",
    "\n",
    "def setup_vgrnn(dim_in, nonlin):\n",
    "    return baseline_models.VGRNN(num_layers=num_layers,\n",
    "                                 dim_in=dim_in,\n",
    "                                 dim_hid=dim_hid)\n",
    "\n",
    "\n",
    "def setup_gen(dim_in, nonlin):\n",
    "    return gen.GEN(num_layers=num_layers,\n",
    "                   dim_in=dim_in,\n",
    "                   dim_hid=dim_hid,\n",
    "                   nonlin=nonlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "loss_fun = gen.GEN_loss()\n",
    "crossent_loss_fun = gen.GEN_loss_crossent()\n",
    "def vgae_loss(model, A, X, delta, Epsilon, state=None):\n",
    "    B = A + Epsilon\n",
    "    # delete all outgoing and incoming edges of deleted nodes\n",
    "    B[delta < -0.5, :] = 0\n",
    "    B[:, delta < -0.5] = 0\n",
    "    loss = model.compute_loss(torch.tensor(A, dtype=torch.float),\n",
    "                              torch.tensor(B, dtype=torch.float),\n",
    "                              torch.tensor(X, dtype=torch.float))\n",
    "\n",
    "    return loss, state\n",
    "\n",
    "\n",
    "def vgrnn_loss(model, A, X, delta, Epsilon, state=None):\n",
    "    A = torch.tensor(A, dtype=torch.float)\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    edge_index, _ = dense_to_sparse(A)\n",
    "\n",
    "    predicted = model(X, edge_index, hidden_in=state)\n",
    "    predicted, state = predicted[:-1], predicted[-1]\n",
    "\n",
    "    target = A + Epsilon\n",
    "    target[delta < -0.5, :] = 0\n",
    "    target[:, delta < -0.5] = 0\n",
    "\n",
    "    return model.compute_loss(*predicted, target), state\n",
    "\n",
    "\n",
    "def gen_loss_crossent(model, A, X, delta, Epsilon, state=None):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float),\n",
    "                                     torch.tensor(X, dtype=torch.float))\n",
    "    loss = crossent_loss_fun(delta_pred, Epsilon_pred,\n",
    "                             torch.tensor(delta, dtype=torch.float),\n",
    "                             torch.tensor(Epsilon, dtype=torch.float),\n",
    "                             torch.tensor(A, dtype=torch.float))\n",
    "\n",
    "    return loss, state\n",
    "\n",
    "\n",
    "def gen_loss(model, A, X, delta, Epsilon, state=None):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float),\n",
    "                                     torch.tensor(X, dtype=torch.float))\n",
    "    loss = loss_fun(delta_pred, Epsilon_pred,\n",
    "                    torch.tensor(delta, dtype=torch.float),\n",
    "                    torch.tensor(Epsilon, dtype=torch.float),\n",
    "                    torch.tensor(A, dtype=torch.float))\n",
    "\n",
    "    return loss, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PREDICTION FUNCTIONS\n",
    "def vgae_pred(model, A, X, state=None):\n",
    "    B = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    B = B.detach().numpy()\n",
    "    Epsilon = B - A\n",
    "    delta = np.zeros(A.shape[0])\n",
    "    delta[np.sum(B, 1) < 0.5] = -1.\n",
    "    Epsilon[delta < -0.5, :] = 0.\n",
    "    Epsilon[:, delta < -0.5] = 0.\n",
    "    return delta, Epsilon, state\n",
    "\n",
    "\n",
    "def vgrnn_pred(model, A, X, state=None):\n",
    "    A = torch.tensor(A, dtype=torch.float)\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    edge_index, _ = dense_to_sparse(A)\n",
    "\n",
    "    predicted = model(X, edge_index, hidden_in=state)\n",
    "    predicted, state = predicted[0], predicted[-1]\n",
    "\n",
    "    n = A.shape[0]\n",
    "    predicted = predicted[:n, :][:, :n].detach().numpy()\n",
    "\n",
    "    Epsilon = predicted - A.numpy()\n",
    "    delta = np.zeros(n)\n",
    "    delta[np.sum(predicted, 1) < 0.5] = -1.\n",
    "    Epsilon[delta < -0.5, :] = 0.\n",
    "    Epsilon[:, delta < -0.5] = 0.\n",
    "\n",
    "    return delta, Epsilon, state\n",
    "\n",
    "\n",
    "def gen_pred(model, A, X, state=None):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    delta_pred = delta_pred.detach().numpy()\n",
    "    Epsilon_pred = Epsilon_pred.detach().numpy()\n",
    "    delta = np.zeros(A.shape[0])\n",
    "    delta[delta_pred > 0.5] = 1.\n",
    "    delta[delta_pred < -0.5] = -1.\n",
    "    Epsilon = np.zeros(A.shape)\n",
    "    Epsilon[np.logical_and(A > 0.5, Epsilon_pred < -0.5)] = -1.\n",
    "    Epsilon[np.logical_and(A < 0.5, Epsilon_pred > +0.5)] = +1.\n",
    "    return delta, Epsilon, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function for VGRNN\n",
    "def pad_xs(xs):\n",
    "    target_len = len(xs)\n",
    "    max_n = max(x.shape[-2] for x in xs)\n",
    "    target_shape = (max_n, xs[0].shape[-1])\n",
    "    output = np.zeros((target_len,) + target_shape, dtype=xs[0].dtype)\n",
    "    for i in range(target_len):\n",
    "        slc = (i,) + tuple(slice(shp) for shp in xs[i].shape)\n",
    "        output[slc] = xs[i]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EVALUATION FUNCTIONS\n",
    "eval_criteria = ['node_ins_recall',\n",
    "                 'node_ins_precision',\n",
    "                 'node_del_recall',\n",
    "                 'node_del_precision',\n",
    "                 'edge_ins_recall',\n",
    "                 'edge_ins_precision',\n",
    "                 'edge_del_recall',\n",
    "                 'edge_del_precision']\n",
    "# set up a function to compute precision and recall\n",
    "def prec_rec(X, Y):\n",
    "    # X is the prediction, Y is the target\n",
    "    target_insertions = Y > 0.5\n",
    "    predicted_insertions = X > 0.5\n",
    "    target_deletions = Y < -0.5\n",
    "    predicted_deletions = X < -0.5\n",
    "    # first, check the insertion recall\n",
    "    if np.sum(target_insertions) < 0.5:\n",
    "        ins_rec = 1.\n",
    "    else:\n",
    "        ins_rec = np.mean(X[target_insertions] > 0.5)\n",
    "    # then the insertion precision\n",
    "    if np.sum(predicted_insertions) < 0.5:\n",
    "        ins_prec = 1.\n",
    "    else:\n",
    "        ins_prec = np.mean(Y[predicted_insertions] > 0.5)\n",
    "    # then the deletion recall\n",
    "    if np.sum(target_deletions) < 0.5:\n",
    "        del_rec = 1.\n",
    "    else:\n",
    "        del_rec = np.mean(X[target_deletions] < -0.5)\n",
    "    # and finally the deletion precision\n",
    "    if np.sum(predicted_deletions) < 0.5:\n",
    "        del_prec = 1.\n",
    "    else:\n",
    "        del_prec = np.mean(Y[predicted_deletions] < -0.5)\n",
    "    return ins_rec, ins_prec, del_rec, del_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_edit_cycles\n",
    "import degree_rules\n",
    "import game_of_life\n",
    "import random\n",
    "\n",
    "\n",
    "# DATASET SETUP\n",
    "def generate_edit_cycle():\n",
    "    As, Xs, tuples = graph_edit_cycles.generate_time_series(random.randrange(3), random.randrange(12), random.randrange(4, 12))\n",
    "    deltas = []\n",
    "    Epsilons = []\n",
    "    for tpl in tuples:\n",
    "        deltas.append(tpl[0])\n",
    "        Epsilons.append(tpl[1])\n",
    "    return As, Xs, deltas, Epsilons\n",
    "\n",
    "\n",
    "def generate_degree_rules():\n",
    "    # the initial number of nodes in each graph\n",
    "    n_init = 8\n",
    "    # the maximum number of nodes that can occur in each graph during evolution\n",
    "    n_max  = n_init * 4\n",
    "    return degree_rules.generate_time_series_from_random_matrix(n_init, n_max = n_max)\n",
    "\n",
    "\n",
    "def generate_game_of_life():\n",
    "    # set hyper-parameters for the game of life random grid generation\n",
    "    grid_size = 10\n",
    "    num_shapes = 1\n",
    "    p = 0.1\n",
    "    T_max = 10\n",
    "    A, Xs, deltas = game_of_life.generate_random_time_series(grid_size, num_shapes, p, T_max)\n",
    "    As = [A] * len(Xs)\n",
    "    Epsilons = [np.zeros_like(A)] * len(Xs)\n",
    "    return As, Xs, deltas, Epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONFIG FOR EXPERIMENTS\n",
    "\n",
    "# Models\n",
    "models = ['VGAE', 'VGRNN', 'GEN_crossent', 'GEN']\n",
    "setup_funs = [setup_vgae, setup_vgrnn, setup_gen, setup_gen]\n",
    "loss_funs = [vgae_loss, vgrnn_loss, gen_loss_crossent, gen_loss]\n",
    "pred_funs = [vgae_pred, vgrnn_pred, gen_pred, gen_pred]\n",
    "\n",
    "# Datasets\n",
    "datasets = ['edit_cycles', 'degree_rules', 'game_of_life']\n",
    "dim_ins  = [4, 32, 1]\n",
    "generator_funs = [generate_edit_cycle, generate_degree_rules, generate_game_of_life]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- data set edit_cycles ---\n",
      "\n",
      "--- model VGAE ---\n",
      "node_ins_recall: 0.653407 +- 0.0344482\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.983871 +- 0.032258\n",
      "node_del_precision: 0.803924 +- 0.131027\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "--- model VGRNN ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 5.47242\n",
      "loss avg after 2000 epochs: 5.47023\n",
      "loss avg after 3000 epochs: 6.245\n",
      "loss avg after 4000 epochs: 5.98484\n",
      "loss avg after 5000 epochs: 5.86518\n",
      "loss avg after 6000 epochs: 5.70864\n",
      "loss avg after 7000 epochs: 5.67238\n",
      "loss avg after 8000 epochs: 5.26569\n",
      "loss avg after 9000 epochs: 5.05257\n",
      "loss avg after 10000 epochs: 5.41263\n",
      "loss avg after 11000 epochs: 5.49596\n",
      "loss avg after 12000 epochs: 6.39\n",
      "loss avg after 13000 epochs: 5.28252\n",
      "loss avg after 14000 epochs: 5.07282\n",
      "loss avg after 15000 epochs: 5.76806\n",
      "loss avg after 16000 epochs: 5.01504\n",
      "loss avg after 17000 epochs: 5.38503\n",
      "loss avg after 18000 epochs: 5.9747\n",
      "loss avg after 19000 epochs: 4.84168\n",
      "loss avg after 20000 epochs: 5.95393\n",
      "loss avg after 21000 epochs: 5.74457\n",
      "loss avg after 22000 epochs: 6.05305\n",
      "loss avg after 23000 epochs: 5.27183\n",
      "loss avg after 24000 epochs: 5.38902\n",
      "loss avg after 25000 epochs: 5.58492\n",
      "loss avg after 26000 epochs: 6.32496\n",
      "loss avg after 27000 epochs: 5.96807\n",
      "loss avg after 28000 epochs: 6.28578\n",
      "loss avg after 29000 epochs: 5.02393\n",
      "loss avg after 30000 epochs: 5.14025\n",
      "loss avg after 31000 epochs: 4.97611\n",
      "loss avg after 32000 epochs: 5.39182\n",
      "loss avg after 33000 epochs: 5.71783\n",
      "loss avg after 34000 epochs: 5.58167\n",
      "loss avg after 35000 epochs: 5.67548\n",
      "loss avg after 36000 epochs: 5.40163\n",
      "loss avg after 37000 epochs: 6.17295\n",
      "loss avg after 38000 epochs: 5.44043\n",
      "loss avg after 39000 epochs: 4.92864\n",
      "loss avg after 40000 epochs: 5.77291\n",
      "loss avg after 41000 epochs: 6.11489\n",
      "loss avg after 42000 epochs: 5.24087\n",
      "loss avg after 43000 epochs: 5.43543\n",
      "loss avg after 44000 epochs: 5.13453\n",
      "loss avg after 45000 epochs: 6.26113\n",
      "loss avg after 46000 epochs: 5.75031\n",
      "loss avg after 47000 epochs: 6.32995\n",
      "loss avg after 48000 epochs: 6.061\n",
      "loss avg after 49000 epochs: 5.53515\n",
      "loss avg after 50000 epochs: 6.18666\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 5.44244\n",
      "loss avg after 2000 epochs: 6.63627\n",
      "loss avg after 3000 epochs: 6.09412\n",
      "loss avg after 4000 epochs: 6.3504\n",
      "loss avg after 5000 epochs: 5.12859\n",
      "loss avg after 6000 epochs: 5.58197\n",
      "loss avg after 7000 epochs: 5.18376\n",
      "loss avg after 8000 epochs: 5.85502\n",
      "loss avg after 9000 epochs: 5.63428\n",
      "loss avg after 10000 epochs: 5.43333\n",
      "loss avg after 11000 epochs: 5.06729\n",
      "loss avg after 12000 epochs: 5.48787\n",
      "loss avg after 13000 epochs: 5.30913\n",
      "loss avg after 14000 epochs: 5.56145\n",
      "loss avg after 15000 epochs: 5.54022\n",
      "loss avg after 16000 epochs: 6.00767\n",
      "loss avg after 17000 epochs: 5.43045\n",
      "loss avg after 18000 epochs: 5.76829\n",
      "loss avg after 19000 epochs: 6.36012\n",
      "loss avg after 20000 epochs: 5.69169\n",
      "loss avg after 21000 epochs: 5.71645\n",
      "loss avg after 22000 epochs: 5.93301\n",
      "loss avg after 23000 epochs: 5.74163\n",
      "loss avg after 24000 epochs: 5.65681\n",
      "loss avg after 25000 epochs: 5.59657\n",
      "loss avg after 26000 epochs: 5.5303\n",
      "loss avg after 27000 epochs: 5.6331\n",
      "loss avg after 28000 epochs: 5.13817\n",
      "loss avg after 29000 epochs: 6.04947\n",
      "loss avg after 30000 epochs: 5.5334\n",
      "loss avg after 31000 epochs: 6.32837\n",
      "loss avg after 32000 epochs: 5.15848\n",
      "loss avg after 33000 epochs: 5.56573\n",
      "loss avg after 34000 epochs: 4.93054\n",
      "loss avg after 35000 epochs: 5.37239\n",
      "loss avg after 36000 epochs: 5.58451\n",
      "loss avg after 37000 epochs: 5.10728\n",
      "loss avg after 38000 epochs: 5.28423\n",
      "loss avg after 39000 epochs: 6.38111\n",
      "loss avg after 40000 epochs: 5.7328\n",
      "loss avg after 41000 epochs: 6.17151\n",
      "loss avg after 42000 epochs: 5.828\n",
      "loss avg after 43000 epochs: 6.40434\n",
      "loss avg after 44000 epochs: 6.03084\n",
      "loss avg after 45000 epochs: 5.61846\n",
      "loss avg after 46000 epochs: 5.66411\n",
      "loss avg after 47000 epochs: 5.82015\n",
      "loss avg after 48000 epochs: 6.03585\n",
      "loss avg after 49000 epochs: 5.21978\n",
      "loss avg after 50000 epochs: 5.8836\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 5.47056\n",
      "loss avg after 2000 epochs: 5.43765\n",
      "loss avg after 3000 epochs: 7.09923\n",
      "loss avg after 4000 epochs: 5.16074\n",
      "loss avg after 5000 epochs: 5.44423\n",
      "loss avg after 6000 epochs: 5.07301\n",
      "loss avg after 7000 epochs: 6.12538\n",
      "loss avg after 8000 epochs: 4.54912\n",
      "loss avg after 9000 epochs: 6.59975\n",
      "loss avg after 10000 epochs: 4.89637\n",
      "loss avg after 11000 epochs: 5.4283\n",
      "loss avg after 12000 epochs: 6.21859\n",
      "loss avg after 13000 epochs: 5.54131\n",
      "loss avg after 14000 epochs: 5.1319\n",
      "loss avg after 15000 epochs: 5.21464\n",
      "loss avg after 16000 epochs: 6.13296\n",
      "loss avg after 17000 epochs: 5.6672\n",
      "loss avg after 18000 epochs: 5.06447\n",
      "loss avg after 19000 epochs: 5.25137\n",
      "loss avg after 20000 epochs: 5.69991\n",
      "loss avg after 21000 epochs: 6.12657\n",
      "loss avg after 22000 epochs: 6.22164\n",
      "loss avg after 23000 epochs: 6.21631\n",
      "loss avg after 24000 epochs: 5.72783\n",
      "loss avg after 25000 epochs: 5.82468\n",
      "loss avg after 26000 epochs: 6.32418\n",
      "loss avg after 27000 epochs: 5.68758\n",
      "loss avg after 28000 epochs: 5.95609\n",
      "loss avg after 29000 epochs: 5.2467\n",
      "loss avg after 30000 epochs: 5.42322\n",
      "loss avg after 31000 epochs: 5.85942\n",
      "loss avg after 32000 epochs: 5.2072\n",
      "loss avg after 33000 epochs: 4.98427\n",
      "loss avg after 34000 epochs: 5.15295\n",
      "loss avg after 35000 epochs: 5.89774\n",
      "loss avg after 36000 epochs: 5.32417\n",
      "loss avg after 37000 epochs: 6.16837\n",
      "loss avg after 38000 epochs: 5.5703\n",
      "loss avg after 39000 epochs: 5.59677\n",
      "loss avg after 40000 epochs: 6.11682\n",
      "loss avg after 41000 epochs: 5.881\n",
      "loss avg after 42000 epochs: 6.17198\n",
      "loss avg after 43000 epochs: 5.82488\n",
      "loss avg after 44000 epochs: 5.14307\n",
      "loss avg after 45000 epochs: 4.90519\n",
      "loss avg after 46000 epochs: 5.73459\n",
      "loss avg after 47000 epochs: 5.98086\n",
      "loss avg after 48000 epochs: 5.32171\n",
      "loss avg after 49000 epochs: 5.47707\n",
      "loss avg after 50000 epochs: 5.9364\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 6.02028\n",
      "loss avg after 2000 epochs: 5.67939\n",
      "loss avg after 3000 epochs: 5.4173\n",
      "loss avg after 4000 epochs: 5.13686\n",
      "loss avg after 5000 epochs: 5.86186\n",
      "loss avg after 6000 epochs: 6.04464\n",
      "loss avg after 7000 epochs: 5.6828\n",
      "loss avg after 8000 epochs: 5.98572\n",
      "loss avg after 9000 epochs: 5.99429\n",
      "loss avg after 10000 epochs: 6.37871\n",
      "loss avg after 11000 epochs: 6.22174\n",
      "loss avg after 12000 epochs: 6.00008\n",
      "loss avg after 13000 epochs: 6.22038\n",
      "loss avg after 14000 epochs: 6.06858\n",
      "loss avg after 15000 epochs: 5.74725\n",
      "loss avg after 16000 epochs: 5.27868\n",
      "loss avg after 17000 epochs: 5.4609\n",
      "loss avg after 18000 epochs: 5.84841\n",
      "loss avg after 19000 epochs: 5.63656\n",
      "loss avg after 20000 epochs: 5.15435\n",
      "loss avg after 21000 epochs: 6.06245\n",
      "loss avg after 22000 epochs: 6.06379\n",
      "loss avg after 23000 epochs: 5.24122\n",
      "loss avg after 24000 epochs: 5.30268\n",
      "loss avg after 25000 epochs: 5.5841\n",
      "loss avg after 26000 epochs: 5.88601\n",
      "loss avg after 27000 epochs: 4.95571\n",
      "loss avg after 28000 epochs: 6.30527\n",
      "loss avg after 29000 epochs: 6.22723\n",
      "loss avg after 30000 epochs: 5.48591\n",
      "loss avg after 31000 epochs: 5.60181\n",
      "loss avg after 32000 epochs: 5.65337\n",
      "loss avg after 33000 epochs: 5.41914\n",
      "loss avg after 34000 epochs: 5.30977\n",
      "loss avg after 35000 epochs: 4.83444\n",
      "loss avg after 36000 epochs: 6.03593\n",
      "loss avg after 37000 epochs: 5.41237\n",
      "loss avg after 38000 epochs: 5.93049\n",
      "loss avg after 39000 epochs: 4.8227\n",
      "loss avg after 40000 epochs: 5.363\n",
      "loss avg after 41000 epochs: 6.34439\n",
      "loss avg after 42000 epochs: 5.62276\n",
      "loss avg after 43000 epochs: 5.83659\n",
      "loss avg after 44000 epochs: 5.80697\n",
      "loss avg after 45000 epochs: 6.26176\n",
      "loss avg after 46000 epochs: 5.47612\n",
      "loss avg after 47000 epochs: 5.5935\n",
      "loss avg after 48000 epochs: 5.96288\n",
      "loss avg after 49000 epochs: 5.40827\n",
      "loss avg after 50000 epochs: 5.4748\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 6.24492\n",
      "loss avg after 2000 epochs: 4.74754\n",
      "loss avg after 3000 epochs: 5.67766\n",
      "loss avg after 4000 epochs: 6.25909\n",
      "loss avg after 5000 epochs: 5.95321\n",
      "loss avg after 6000 epochs: 5.42324\n",
      "loss avg after 7000 epochs: 5.72902\n",
      "loss avg after 8000 epochs: 5.47816\n",
      "loss avg after 9000 epochs: 5.7697\n",
      "loss avg after 10000 epochs: 5.4696\n",
      "loss avg after 11000 epochs: 5.33198\n",
      "loss avg after 12000 epochs: 6.16622\n",
      "loss avg after 13000 epochs: 5.8031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss avg after 14000 epochs: 6.045\n",
      "loss avg after 15000 epochs: 6.02037\n",
      "loss avg after 16000 epochs: 6.06009\n",
      "loss avg after 17000 epochs: 5.76344\n",
      "loss avg after 18000 epochs: 5.43921\n",
      "loss avg after 19000 epochs: 5.13954\n",
      "loss avg after 20000 epochs: 5.49525\n",
      "loss avg after 21000 epochs: 5.94155\n",
      "loss avg after 22000 epochs: 5.81894\n",
      "loss avg after 23000 epochs: 5.54514\n",
      "loss avg after 24000 epochs: 6.69348\n",
      "loss avg after 25000 epochs: 5.00692\n",
      "loss avg after 26000 epochs: 6.21436\n",
      "loss avg after 27000 epochs: 6.13624\n",
      "loss avg after 28000 epochs: 5.78238\n",
      "loss avg after 29000 epochs: 5.62429\n",
      "loss avg after 30000 epochs: 5.45688\n",
      "loss avg after 31000 epochs: 5.85331\n",
      "loss avg after 32000 epochs: 6.45893\n",
      "loss avg after 33000 epochs: 5.7255\n",
      "loss avg after 34000 epochs: 6.61136\n",
      "loss avg after 35000 epochs: 6.35065\n",
      "loss avg after 36000 epochs: 5.99933\n",
      "loss avg after 37000 epochs: 5.4338\n",
      "loss avg after 38000 epochs: 5.54456\n",
      "loss avg after 39000 epochs: 5.86461\n",
      "loss avg after 40000 epochs: 5.73404\n",
      "loss avg after 41000 epochs: 5.19054\n",
      "loss avg after 42000 epochs: 5.64245\n",
      "loss avg after 43000 epochs: 5.90309\n",
      "loss avg after 44000 epochs: 5.68169\n",
      "loss avg after 45000 epochs: 6.39032\n",
      "loss avg after 46000 epochs: 5.67506\n",
      "loss avg after 47000 epochs: 5.07207\n",
      "loss avg after 48000 epochs: 5.58894\n",
      "loss avg after 49000 epochs: 5.86341\n",
      "loss avg after 50000 epochs: 6.16573\n",
      "node_ins_recall: 0.656057 +- 0.0294586\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.648058 +- 0.0335645\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 0.957213 +- 0.0332931\n",
      "edge_ins_precision: 0.0692052 +- 0.013444\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.718422 +- 0.072305\n",
      "--- model GEN_crossent ---\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "--- model GEN ---\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "\n",
      "--- data set degree_rules ---\n",
      "\n",
      "--- model VGAE ---\n",
      "node_ins_recall: 0.12867 +- 0.0121697\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 0.958187 +- 0.0213677\n",
      "edge_ins_recall: 0.873701 +- 0.0450202\n",
      "edge_ins_precision: 0.96103 +- 0.0684192\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.938462 +- 0.123077\n",
      "--- model VGRNN ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 8.50927\n",
      "loss avg after 2000 epochs: 8.89737\n",
      "loss avg after 3000 epochs: 7.95499\n",
      "loss avg after 4000 epochs: 8.52116\n",
      "loss avg after 5000 epochs: 8.77432\n",
      "loss avg after 6000 epochs: 7.97237\n",
      "loss avg after 7000 epochs: 8.34444\n",
      "loss avg after 8000 epochs: 8.4733\n",
      "loss avg after 9000 epochs: 8.24101\n",
      "loss avg after 10000 epochs: 7.48355\n",
      "loss avg after 11000 epochs: 8.31454\n",
      "loss avg after 12000 epochs: 8.11758\n",
      "loss avg after 13000 epochs: 8.22735\n",
      "loss avg after 14000 epochs: 8.14117\n",
      "loss avg after 15000 epochs: 8.51521\n",
      "loss avg after 16000 epochs: 7.84011\n",
      "loss avg after 17000 epochs: 7.52256\n",
      "loss avg after 18000 epochs: 7.37569\n",
      "loss avg after 19000 epochs: 7.07071\n",
      "loss avg after 20000 epochs: 8.11521\n",
      "loss avg after 21000 epochs: 7.69081\n",
      "loss avg after 22000 epochs: 7.95112\n",
      "loss avg after 23000 epochs: 7.79027\n",
      "loss avg after 24000 epochs: 7.62287\n",
      "loss avg after 25000 epochs: 7.58227\n",
      "loss avg after 26000 epochs: 7.55544\n",
      "loss avg after 27000 epochs: 7.45941\n",
      "loss avg after 28000 epochs: 7.54787\n",
      "loss avg after 29000 epochs: 7.34253\n",
      "loss avg after 30000 epochs: 7.92919\n",
      "loss avg after 31000 epochs: 7.24558\n",
      "loss avg after 32000 epochs: 7.74589\n",
      "loss avg after 33000 epochs: 7.55443\n",
      "loss avg after 34000 epochs: 8.06722\n",
      "loss avg after 35000 epochs: 7.88577\n",
      "loss avg after 36000 epochs: 7.79312\n",
      "loss avg after 37000 epochs: 7.55544\n",
      "loss avg after 38000 epochs: 7.99739\n",
      "loss avg after 39000 epochs: 7.51674\n",
      "loss avg after 40000 epochs: 8.02602\n",
      "loss avg after 41000 epochs: 7.40634\n",
      "loss avg after 42000 epochs: 7.0661\n",
      "loss avg after 43000 epochs: 7.33643\n",
      "loss avg after 44000 epochs: 7.76219\n",
      "loss avg after 45000 epochs: 8.06601\n",
      "loss avg after 46000 epochs: 7.13991\n",
      "loss avg after 47000 epochs: 7.58165\n",
      "loss avg after 48000 epochs: 7.38666\n",
      "loss avg after 49000 epochs: 7.22382\n",
      "loss avg after 50000 epochs: 7.58776\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 8.16542\n",
      "loss avg after 2000 epochs: 7.63421\n",
      "loss avg after 3000 epochs: 7.92043\n",
      "loss avg after 4000 epochs: 8.07198\n",
      "loss avg after 5000 epochs: 8.49799\n",
      "loss avg after 6000 epochs: 7.97417\n",
      "loss avg after 7000 epochs: 8.90933\n",
      "loss avg after 8000 epochs: 8.1324\n",
      "loss avg after 9000 epochs: 7.14191\n",
      "loss avg after 10000 epochs: 7.46542\n",
      "loss avg after 11000 epochs: 8.06069\n",
      "loss avg after 12000 epochs: 8.59149\n",
      "loss avg after 13000 epochs: 8.21929\n",
      "loss avg after 14000 epochs: 8.09107\n",
      "loss avg after 15000 epochs: 9.16694\n",
      "loss avg after 16000 epochs: 8.04548\n",
      "loss avg after 17000 epochs: 8.08546\n",
      "loss avg after 18000 epochs: 7.9767\n",
      "loss avg after 19000 epochs: 7.75419\n",
      "loss avg after 20000 epochs: 7.58954\n",
      "loss avg after 21000 epochs: 7.92638\n",
      "loss avg after 22000 epochs: 7.50902\n",
      "loss avg after 23000 epochs: 7.67939\n",
      "loss avg after 24000 epochs: 7.51825\n",
      "loss avg after 25000 epochs: 8.05301\n",
      "loss avg after 26000 epochs: 7.58555\n",
      "loss avg after 27000 epochs: 7.96036\n",
      "loss avg after 28000 epochs: 8.18183\n",
      "loss avg after 29000 epochs: 7.08608\n",
      "loss avg after 30000 epochs: 7.85677\n",
      "loss avg after 31000 epochs: 7.1878\n",
      "loss avg after 32000 epochs: 7.46894\n",
      "loss avg after 33000 epochs: 7.2113\n",
      "loss avg after 34000 epochs: 7.3026\n",
      "loss avg after 35000 epochs: 7.80036\n",
      "loss avg after 36000 epochs: 7.7584\n",
      "loss avg after 37000 epochs: 7.50702\n",
      "loss avg after 38000 epochs: 7.84226\n",
      "loss avg after 39000 epochs: 7.53493\n",
      "loss avg after 40000 epochs: 7.86372\n",
      "loss avg after 41000 epochs: 7.80272\n",
      "loss avg after 42000 epochs: 7.84955\n",
      "loss avg after 43000 epochs: 7.78929\n",
      "loss avg after 44000 epochs: 7.68951\n",
      "loss avg after 45000 epochs: 7.77959\n",
      "loss avg after 46000 epochs: 7.37861\n",
      "loss avg after 47000 epochs: 8.13835\n",
      "loss avg after 48000 epochs: 7.74849\n",
      "loss avg after 49000 epochs: 7.61723\n",
      "loss avg after 50000 epochs: 7.99276\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 8.25803\n",
      "loss avg after 2000 epochs: 7.80056\n",
      "loss avg after 3000 epochs: 7.66091\n",
      "loss avg after 4000 epochs: 8.32187\n",
      "loss avg after 5000 epochs: 8.25219\n",
      "loss avg after 6000 epochs: 8.72622\n",
      "loss avg after 7000 epochs: 8.03181\n",
      "loss avg after 8000 epochs: 8.49464\n",
      "loss avg after 9000 epochs: 7.68209\n",
      "loss avg after 10000 epochs: 8.79722\n",
      "loss avg after 11000 epochs: 7.94715\n",
      "loss avg after 12000 epochs: 8.16767\n",
      "loss avg after 13000 epochs: 8.0146\n",
      "loss avg after 14000 epochs: 8.02557\n",
      "loss avg after 15000 epochs: 7.59175\n",
      "loss avg after 16000 epochs: 8.36093\n",
      "loss avg after 17000 epochs: 7.95863\n",
      "loss avg after 18000 epochs: 7.81684\n",
      "loss avg after 19000 epochs: 7.56735\n",
      "loss avg after 20000 epochs: 7.94397\n",
      "loss avg after 21000 epochs: 7.26943\n",
      "loss avg after 22000 epochs: 7.72699\n",
      "loss avg after 23000 epochs: 7.65007\n",
      "loss avg after 24000 epochs: 7.3229\n",
      "loss avg after 25000 epochs: 8.02881\n",
      "loss avg after 26000 epochs: 7.51847\n",
      "loss avg after 27000 epochs: 7.9418\n",
      "loss avg after 28000 epochs: 7.63298\n",
      "loss avg after 29000 epochs: 7.56403\n",
      "loss avg after 30000 epochs: 7.59213\n",
      "loss avg after 31000 epochs: 7.14926\n",
      "loss avg after 32000 epochs: 7.29905\n",
      "loss avg after 33000 epochs: 7.66916\n",
      "loss avg after 34000 epochs: 7.648\n",
      "loss avg after 35000 epochs: 7.46572\n",
      "loss avg after 36000 epochs: 7.5622\n",
      "loss avg after 37000 epochs: 8.16309\n",
      "loss avg after 38000 epochs: 7.43253\n",
      "loss avg after 39000 epochs: 8.07446\n",
      "loss avg after 40000 epochs: 7.88333\n",
      "loss avg after 41000 epochs: 7.88312\n",
      "loss avg after 42000 epochs: 7.7947\n",
      "loss avg after 43000 epochs: 7.58729\n",
      "loss avg after 44000 epochs: 7.76732\n",
      "loss avg after 45000 epochs: 7.62194\n",
      "loss avg after 46000 epochs: 7.9969\n",
      "loss avg after 47000 epochs: 7.428\n",
      "loss avg after 48000 epochs: 7.49209\n",
      "loss avg after 49000 epochs: 7.90885\n",
      "loss avg after 50000 epochs: 7.32641\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 7.56127\n",
      "loss avg after 2000 epochs: 8.62493\n",
      "loss avg after 3000 epochs: 8.93867\n",
      "loss avg after 4000 epochs: 8.52242\n",
      "loss avg after 5000 epochs: 8.48348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss avg after 6000 epochs: 8.61882\n",
      "loss avg after 7000 epochs: 8.32989\n",
      "loss avg after 8000 epochs: 8.30106\n",
      "loss avg after 9000 epochs: 8.04884\n",
      "loss avg after 10000 epochs: 8.69912\n",
      "loss avg after 11000 epochs: 8.50798\n",
      "loss avg after 12000 epochs: 8.21513\n",
      "loss avg after 13000 epochs: 8.22318\n",
      "loss avg after 14000 epochs: 7.67616\n",
      "loss avg after 15000 epochs: 7.76724\n",
      "loss avg after 16000 epochs: 8.12565\n",
      "loss avg after 17000 epochs: 8.19194\n",
      "loss avg after 18000 epochs: 7.22552\n",
      "loss avg after 19000 epochs: 7.27982\n",
      "loss avg after 20000 epochs: 8.54416\n",
      "loss avg after 21000 epochs: 7.43262\n",
      "loss avg after 22000 epochs: 7.97145\n",
      "loss avg after 23000 epochs: 7.88548\n",
      "loss avg after 24000 epochs: 7.63718\n",
      "loss avg after 25000 epochs: 7.61813\n",
      "loss avg after 26000 epochs: 7.72526\n",
      "loss avg after 27000 epochs: 7.76815\n",
      "loss avg after 28000 epochs: 7.60908\n",
      "loss avg after 29000 epochs: 7.26438\n",
      "loss avg after 30000 epochs: 7.59843\n",
      "loss avg after 31000 epochs: 7.29211\n",
      "loss avg after 32000 epochs: 7.63401\n",
      "loss avg after 33000 epochs: 6.75677\n",
      "loss avg after 34000 epochs: 7.66722\n",
      "loss avg after 35000 epochs: 7.91423\n",
      "loss avg after 36000 epochs: 7.47326\n",
      "loss avg after 37000 epochs: 7.6286\n",
      "loss avg after 38000 epochs: 7.78096\n",
      "loss avg after 39000 epochs: 8.01241\n",
      "loss avg after 40000 epochs: 7.86509\n",
      "loss avg after 41000 epochs: 7.67705\n",
      "loss avg after 42000 epochs: 7.75672\n",
      "loss avg after 43000 epochs: 7.83974\n",
      "loss avg after 44000 epochs: 7.58276\n",
      "loss avg after 45000 epochs: 7.71369\n",
      "loss avg after 46000 epochs: 7.73964\n",
      "loss avg after 47000 epochs: 7.07595\n",
      "loss avg after 48000 epochs: 7.60083\n",
      "loss avg after 49000 epochs: 6.95109\n",
      "loss avg after 50000 epochs: 7.17743\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 8.26979\n",
      "loss avg after 2000 epochs: 7.82319\n",
      "loss avg after 3000 epochs: 8.50838\n",
      "loss avg after 4000 epochs: 8.11865\n",
      "loss avg after 5000 epochs: 8.66543\n",
      "loss avg after 6000 epochs: 7.88789\n",
      "loss avg after 7000 epochs: 7.97013\n",
      "loss avg after 8000 epochs: 8.13182\n",
      "loss avg after 9000 epochs: 7.93847\n",
      "loss avg after 10000 epochs: 8.63585\n",
      "loss avg after 11000 epochs: 9.23521\n",
      "loss avg after 12000 epochs: 8.28603\n",
      "loss avg after 13000 epochs: 8.81011\n",
      "loss avg after 14000 epochs: 8.70164\n",
      "loss avg after 15000 epochs: 8.04092\n",
      "loss avg after 16000 epochs: 7.85321\n",
      "loss avg after 17000 epochs: 8.7963\n",
      "loss avg after 18000 epochs: 7.67276\n",
      "loss avg after 19000 epochs: 7.13555\n",
      "loss avg after 20000 epochs: 7.76535\n",
      "loss avg after 21000 epochs: 7.95486\n",
      "loss avg after 22000 epochs: 8.03958\n",
      "loss avg after 23000 epochs: 8.1892\n",
      "loss avg after 24000 epochs: 7.51121\n",
      "loss avg after 25000 epochs: 7.38521\n",
      "loss avg after 26000 epochs: 8.06127\n",
      "loss avg after 27000 epochs: 7.54566\n",
      "loss avg after 28000 epochs: 7.46138\n",
      "loss avg after 29000 epochs: 7.46882\n",
      "loss avg after 30000 epochs: 7.4175\n",
      "loss avg after 31000 epochs: 7.25982\n",
      "loss avg after 32000 epochs: 7.49638\n",
      "loss avg after 33000 epochs: 7.35724\n",
      "loss avg after 34000 epochs: 7.64158\n",
      "loss avg after 35000 epochs: 7.82047\n",
      "loss avg after 36000 epochs: 7.48773\n",
      "loss avg after 37000 epochs: 7.46139\n",
      "loss avg after 38000 epochs: 7.80484\n",
      "loss avg after 39000 epochs: 7.17055\n",
      "loss avg after 40000 epochs: 7.55104\n",
      "loss avg after 41000 epochs: 7.46258\n",
      "loss avg after 42000 epochs: 7.7334\n",
      "loss avg after 43000 epochs: 7.49893\n",
      "loss avg after 44000 epochs: 7.88123\n",
      "loss avg after 45000 epochs: 7.451\n",
      "loss avg after 46000 epochs: 7.1891\n",
      "loss avg after 47000 epochs: 7.38665\n",
      "loss avg after 48000 epochs: 8.04393\n",
      "loss avg after 49000 epochs: 7.53209\n",
      "loss avg after 50000 epochs: 8.08147\n",
      "node_ins_recall: 0.130664 +- 0.01273\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.727067 +- 0.0123854\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 0.556062 +- 0.0340379\n",
      "edge_ins_precision: 0.195062 +- 0.0297426\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.00790699 +- 0.00746227\n",
      "--- model GEN_crossent ---\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 0.999728 +- 0.0005444\n",
      "node_del_recall: 0.995906 +- 0.0081872\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 0.923877 +- 0.0944398\n",
      "edge_ins_precision: 0.968968 +- 0.0187307\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.99619 +- 0.0076192\n",
      "--- model GEN ---\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 0.998466 +- 0.003068\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 0.966329 +- 0.0395248\n",
      "edge_ins_precision: 0.976981 +- 0.0216862\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.998095 +- 0.0038096\n",
      "\n",
      "--- data set game_of_life ---\n",
      "\n",
      "--- model VGAE ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 62605.3\n",
      "loss avg after 2000 epochs: 40447.5\n",
      "loss avg after 3000 epochs: 30484.1\n",
      "loss avg after 4000 epochs: 25780.6\n",
      "loss avg after 5000 epochs: 23362.1\n",
      "loss avg after 6000 epochs: 21990.2\n",
      "loss avg after 7000 epochs: 21673.9\n",
      "loss avg after 8000 epochs: 21027.5\n",
      "loss avg after 9000 epochs: 21183.1\n",
      "loss avg after 10000 epochs: 20908.7\n",
      "loss avg after 11000 epochs: 20916\n",
      "loss avg after 12000 epochs: 19938.7\n",
      "loss avg after 13000 epochs: 20839.5\n",
      "loss avg after 14000 epochs: 20110.7\n",
      "loss avg after 15000 epochs: 20029\n",
      "loss avg after 16000 epochs: 20178.3\n",
      "loss avg after 17000 epochs: 20482.5\n",
      "loss avg after 18000 epochs: 21054.4\n",
      "loss avg after 19000 epochs: 20042.7\n",
      "loss avg after 20000 epochs: 20165.7\n",
      "loss avg after 21000 epochs: 19715.5\n",
      "loss avg after 22000 epochs: 19605.6\n",
      "loss avg after 23000 epochs: 19946.8\n",
      "loss avg after 24000 epochs: 20270.6\n",
      "loss avg after 25000 epochs: 19472.1\n",
      "loss avg after 26000 epochs: 20038.5\n",
      "loss avg after 27000 epochs: 20108.7\n",
      "loss avg after 28000 epochs: 20159\n",
      "loss avg after 29000 epochs: 20073.2\n",
      "loss avg after 30000 epochs: 19882\n",
      "loss avg after 31000 epochs: 19086\n",
      "loss avg after 32000 epochs: 19760.7\n",
      "loss avg after 33000 epochs: 20205.7\n",
      "loss avg after 34000 epochs: 19735.5\n",
      "loss avg after 35000 epochs: 20009.9\n",
      "loss avg after 36000 epochs: 19060.7\n",
      "loss avg after 37000 epochs: 19927.7\n",
      "loss avg after 38000 epochs: 20373.1\n",
      "loss avg after 39000 epochs: 19463.8\n",
      "loss avg after 40000 epochs: 19489.9\n",
      "loss avg after 41000 epochs: 19991.3\n",
      "loss avg after 42000 epochs: 19937.5\n",
      "loss avg after 43000 epochs: 19570\n",
      "loss avg after 44000 epochs: 20303.7\n",
      "loss avg after 45000 epochs: 19673.3\n",
      "loss avg after 46000 epochs: 19856.6\n",
      "loss avg after 47000 epochs: 19183.4\n",
      "loss avg after 48000 epochs: 19725.1\n",
      "loss avg after 49000 epochs: 18771.7\n",
      "loss avg after 50000 epochs: 19205.9\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 27984.4\n",
      "loss avg after 2000 epochs: 23873.3\n",
      "loss avg after 3000 epochs: 22517.9\n",
      "loss avg after 4000 epochs: 21010.3\n",
      "loss avg after 5000 epochs: 21358.8\n",
      "loss avg after 6000 epochs: 20905.3\n",
      "loss avg after 7000 epochs: 20915.9\n",
      "loss avg after 8000 epochs: 20620.9\n",
      "loss avg after 9000 epochs: 20331.8\n",
      "loss avg after 10000 epochs: 20765.6\n",
      "loss avg after 11000 epochs: 21111.8\n",
      "loss avg after 12000 epochs: 20405.6\n",
      "loss avg after 13000 epochs: 19843.2\n",
      "loss avg after 14000 epochs: 20101.2\n",
      "loss avg after 15000 epochs: 19491.6\n",
      "loss avg after 16000 epochs: 20503.5\n",
      "loss avg after 17000 epochs: 19717.8\n",
      "loss avg after 18000 epochs: 19754.1\n",
      "loss avg after 19000 epochs: 19752.3\n",
      "loss avg after 20000 epochs: 20091.5\n",
      "loss avg after 21000 epochs: 19760.1\n",
      "loss avg after 22000 epochs: 19130.1\n",
      "loss avg after 23000 epochs: 18851.3\n",
      "loss avg after 24000 epochs: 19767.8\n",
      "loss avg after 25000 epochs: 20226.3\n",
      "loss avg after 26000 epochs: 20049.3\n",
      "loss avg after 27000 epochs: 19419.1\n",
      "loss avg after 28000 epochs: 19598\n",
      "loss avg after 29000 epochs: 19216.5\n",
      "loss avg after 30000 epochs: 20094.1\n",
      "loss avg after 31000 epochs: 19346.8\n",
      "loss avg after 32000 epochs: 19297.1\n",
      "loss avg after 33000 epochs: 19538.8\n",
      "loss avg after 34000 epochs: 19623.8\n",
      "loss avg after 35000 epochs: 18817.3\n",
      "loss avg after 36000 epochs: 19852.8\n",
      "loss avg after 37000 epochs: 19101.7\n",
      "loss avg after 38000 epochs: 18739.8\n",
      "loss avg after 39000 epochs: 19228.6\n",
      "loss avg after 40000 epochs: 19310.4\n",
      "loss avg after 41000 epochs: 19587.7\n",
      "loss avg after 42000 epochs: 20276.6\n",
      "loss avg after 43000 epochs: 19003.4\n",
      "loss avg after 44000 epochs: 19053.8\n",
      "loss avg after 45000 epochs: 20107.1\n",
      "loss avg after 46000 epochs: 19491.4\n",
      "loss avg after 47000 epochs: 19871.1\n",
      "loss avg after 48000 epochs: 19970.6\n",
      "loss avg after 49000 epochs: 19507.1\n",
      "loss avg after 50000 epochs: 20247.8\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 45298.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss avg after 2000 epochs: 31950.5\n",
      "loss avg after 3000 epochs: 26336.8\n",
      "loss avg after 4000 epochs: 23857.8\n",
      "loss avg after 5000 epochs: 22095.9\n",
      "loss avg after 6000 epochs: 21778\n",
      "loss avg after 7000 epochs: 21281.8\n",
      "loss avg after 8000 epochs: 20995.5\n",
      "loss avg after 9000 epochs: 20418.3\n",
      "loss avg after 10000 epochs: 20751.1\n",
      "loss avg after 11000 epochs: 20196.4\n",
      "loss avg after 12000 epochs: 20329.7\n",
      "loss avg after 13000 epochs: 20606\n",
      "loss avg after 14000 epochs: 20482.9\n",
      "loss avg after 15000 epochs: 20759.6\n",
      "loss avg after 16000 epochs: 20314.1\n",
      "loss avg after 17000 epochs: 20846.8\n",
      "loss avg after 18000 epochs: 20483.3\n",
      "loss avg after 19000 epochs: 20151.7\n",
      "loss avg after 20000 epochs: 19855.8\n",
      "loss avg after 21000 epochs: 19927.6\n",
      "loss avg after 22000 epochs: 20214.1\n",
      "loss avg after 23000 epochs: 20238.9\n",
      "loss avg after 24000 epochs: 20140.1\n",
      "loss avg after 25000 epochs: 19539.5\n",
      "loss avg after 26000 epochs: 19697.9\n",
      "loss avg after 27000 epochs: 19445.7\n",
      "loss avg after 28000 epochs: 19517.8\n",
      "loss avg after 29000 epochs: 19471.3\n",
      "loss avg after 30000 epochs: 20284.4\n",
      "loss avg after 31000 epochs: 20363.4\n",
      "loss avg after 32000 epochs: 19738.6\n",
      "loss avg after 33000 epochs: 19830.3\n",
      "loss avg after 34000 epochs: 20133.9\n",
      "loss avg after 35000 epochs: 19975.4\n",
      "loss avg after 36000 epochs: 19970.6\n",
      "loss avg after 37000 epochs: 20253.3\n",
      "loss avg after 38000 epochs: 19056.6\n",
      "loss avg after 39000 epochs: 20057.7\n",
      "loss avg after 40000 epochs: 19755\n",
      "loss avg after 41000 epochs: 18672.7\n",
      "loss avg after 42000 epochs: 19436.8\n",
      "loss avg after 43000 epochs: 19651.2\n",
      "loss avg after 44000 epochs: 19398.9\n",
      "loss avg after 45000 epochs: 19304.2\n",
      "loss avg after 46000 epochs: 18968.4\n",
      "loss avg after 47000 epochs: 19675.2\n",
      "loss avg after 48000 epochs: 19508.8\n",
      "loss avg after 49000 epochs: 19498.8\n",
      "loss avg after 50000 epochs: 19249.3\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 23664.7\n",
      "loss avg after 2000 epochs: 23503.5\n",
      "loss avg after 3000 epochs: 23573.5\n",
      "loss avg after 4000 epochs: 23344.8\n",
      "loss avg after 5000 epochs: 23133.9\n",
      "loss avg after 6000 epochs: 23038\n",
      "loss avg after 7000 epochs: 22946.1\n",
      "loss avg after 8000 epochs: 23214.6\n",
      "loss avg after 9000 epochs: 22909.4\n",
      "loss avg after 10000 epochs: 23052.8\n",
      "loss avg after 11000 epochs: 22721.4\n",
      "loss avg after 12000 epochs: 22731.3\n",
      "loss avg after 13000 epochs: 23038.9\n",
      "loss avg after 14000 epochs: 23000.6\n",
      "loss avg after 15000 epochs: 22875.8\n",
      "loss avg after 16000 epochs: 22979.7\n",
      "loss avg after 17000 epochs: 22825.4\n",
      "loss avg after 18000 epochs: 22544.1\n",
      "loss avg after 19000 epochs: 22724.1\n",
      "loss avg after 20000 epochs: 22308\n",
      "loss avg after 21000 epochs: 22026.2\n",
      "loss avg after 22000 epochs: 22595.9\n",
      "loss avg after 23000 epochs: 22480.1\n",
      "loss avg after 24000 epochs: 22454.3\n",
      "loss avg after 25000 epochs: 22610.6\n",
      "loss avg after 26000 epochs: 22476.6\n",
      "loss avg after 27000 epochs: 22432.8\n",
      "loss avg after 28000 epochs: 22576.7\n",
      "loss avg after 29000 epochs: 22408\n",
      "loss avg after 30000 epochs: 22274.8\n",
      "loss avg after 31000 epochs: 22319.4\n",
      "loss avg after 32000 epochs: 22389\n",
      "loss avg after 33000 epochs: 22462.7\n",
      "loss avg after 34000 epochs: 21843\n",
      "loss avg after 35000 epochs: 22501.7\n",
      "loss avg after 36000 epochs: 22090.2\n",
      "loss avg after 37000 epochs: 22202.5\n",
      "loss avg after 38000 epochs: 22365\n",
      "loss avg after 39000 epochs: 22446.8\n",
      "loss avg after 40000 epochs: 22173.1\n",
      "loss avg after 41000 epochs: 22125.6\n",
      "loss avg after 42000 epochs: 22501.2\n",
      "loss avg after 43000 epochs: 22273.8\n",
      "loss avg after 44000 epochs: 22198.9\n",
      "loss avg after 45000 epochs: 22380.9\n",
      "loss avg after 46000 epochs: 21988.3\n",
      "loss avg after 47000 epochs: 21902.1\n",
      "loss avg after 48000 epochs: 22282\n",
      "loss avg after 49000 epochs: 22410.5\n",
      "loss avg after 50000 epochs: 21972.7\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 33195.9\n",
      "loss avg after 2000 epochs: 26469.7\n",
      "loss avg after 3000 epochs: 23924\n",
      "loss avg after 4000 epochs: 22230\n",
      "loss avg after 5000 epochs: 21444.1\n",
      "loss avg after 6000 epochs: 21121.8\n",
      "loss avg after 7000 epochs: 21072.8\n",
      "loss avg after 8000 epochs: 20283.2\n",
      "loss avg after 9000 epochs: 20971.4\n",
      "loss avg after 10000 epochs: 20853\n",
      "loss avg after 11000 epochs: 20402.8\n",
      "loss avg after 12000 epochs: 20542.3\n",
      "loss avg after 13000 epochs: 21023\n",
      "loss avg after 14000 epochs: 20979\n",
      "loss avg after 15000 epochs: 20824.6\n",
      "loss avg after 16000 epochs: 20269.7\n",
      "loss avg after 17000 epochs: 20318.4\n",
      "loss avg after 18000 epochs: 19304.6\n",
      "loss avg after 19000 epochs: 19872.1\n",
      "loss avg after 20000 epochs: 19722.6\n",
      "loss avg after 21000 epochs: 19676\n",
      "loss avg after 22000 epochs: 19807.7\n",
      "loss avg after 23000 epochs: 19461.4\n",
      "loss avg after 24000 epochs: 20102\n",
      "loss avg after 25000 epochs: 20755.1\n",
      "loss avg after 26000 epochs: 20112.8\n",
      "loss avg after 27000 epochs: 19843.5\n",
      "loss avg after 28000 epochs: 20014.1\n",
      "loss avg after 29000 epochs: 19678.6\n",
      "loss avg after 30000 epochs: 20284\n",
      "loss avg after 31000 epochs: 19977.1\n",
      "loss avg after 32000 epochs: 19129.8\n",
      "loss avg after 33000 epochs: 19606.4\n",
      "loss avg after 34000 epochs: 19621.8\n",
      "loss avg after 35000 epochs: 19685.6\n",
      "loss avg after 36000 epochs: 19516.3\n",
      "loss avg after 37000 epochs: 20554.9\n",
      "loss avg after 38000 epochs: 19431.2\n",
      "loss avg after 39000 epochs: 19288.3\n",
      "loss avg after 40000 epochs: 19952.2\n",
      "loss avg after 41000 epochs: 19667.1\n",
      "loss avg after 42000 epochs: 19475.8\n",
      "loss avg after 43000 epochs: 19914.2\n",
      "loss avg after 44000 epochs: 19278.9\n",
      "loss avg after 45000 epochs: 19400\n",
      "loss avg after 46000 epochs: 19022\n",
      "loss avg after 47000 epochs: 18951.1\n",
      "loss avg after 48000 epochs: 19205.9\n",
      "loss avg after 49000 epochs: 19857.8\n",
      "loss avg after 50000 epochs: 19415.6\n",
      "node_ins_recall: 0.186 +- 0.0458694\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 0.0448989 +- 0.00658438\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 0.22 +- 0.166493\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.206 +- 0.130935\n",
      "--- model VGRNN ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 7.14403\n",
      "loss avg after 2000 epochs: 7.00025\n",
      "loss avg after 3000 epochs: 6.96768\n",
      "loss avg after 4000 epochs: 6.96979\n",
      "loss avg after 5000 epochs: 6.97935\n",
      "loss avg after 6000 epochs: 6.93794\n",
      "loss avg after 7000 epochs: 6.98101\n",
      "loss avg after 8000 epochs: 6.91761\n",
      "loss avg after 9000 epochs: 6.91309\n",
      "loss avg after 10000 epochs: 6.93837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3c88a485b4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mloss_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_funs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEpsilons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mloss_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-47e8fea927d2>\u001b[0m in \u001b[0;36mvgrnn_loss\u001b[0;34m(model, A, X, delta, Epsilon, state)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_to_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GIT/graph-edit-networks/baseline_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_idx, hidden_in)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# recurrence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphi_x_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_z\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GIT/graph-edit-networks/baseline_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, edgidx, h)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mz_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_xz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mr_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_xr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mh_tilde_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_xh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_g\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0mh_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_g\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mz_g\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_tilde_g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m#         out = self.decoder(h_t.view(1,-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m    185\u001b[0m                              size=None)\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    print('\\n--- data set %s ---\\n' % datasets[d])\n",
    "    # load partial runtime results if possible\n",
    "    runtimes_file = 'results/%s_runtimes.csv' % datasets[d]\n",
    "    if os.path.exists(runtimes_file):\n",
    "        runtimes = np.loadtxt(runtimes_file, skiprows=1, delimiter='\\t')\n",
    "    else:\n",
    "        runtimes = np.full((R, len(models)), np.nan)\n",
    "    # iterate over all models\n",
    "    for k in range(len(models)):\n",
    "        print('--- model %s ---' % models[k])\n",
    "        # load partial results if possible\n",
    "        results_file = 'results/%s_%s_results.csv' % (datasets[d], models[k])\n",
    "        curves_file = 'results/%s_%s_learning_curves.csv' % (datasets[d], models[k])\n",
    "        if os.path.exists(results_file):\n",
    "            results = np.loadtxt(results_file, skiprows=1, delimiter='\\t')\n",
    "            learning_curves = np.loadtxt(curves_file, delimiter='\\t')\n",
    "        else:\n",
    "            results = np.full((R, len(eval_criteria)), np.nan)\n",
    "            learning_curves = np.full((max_epochs, R), np.nan)\n",
    "        # iterate over experimental repeats\n",
    "        for r in range(R):\n",
    "            # check if this repeat is already evaluated; if so, skip it\n",
    "            if not np.isnan(learning_curves[0, r]):\n",
    "                continue\n",
    "            print('-- repeat %d of %d --' % (r + 1, R))\n",
    "            start_time = time.time()\n",
    "            # set up model\n",
    "            if datasets[d] == 'game_of_life':\n",
    "                nonlin = torch.nn.Sigmoid()\n",
    "            else:\n",
    "                nonlin = torch.nn.ReLU()\n",
    "            model = setup_funs[k](dim_ins[d], nonlin)\n",
    "            # set up optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            # initialize moving loss average for printing\n",
    "            loss_avg = None\n",
    "            # start training\n",
    "            for epoch in range(max_epochs):\n",
    "                optimizer.zero_grad()\n",
    "                # sample a time series from the data set\n",
    "                As, Xs, deltas, Epsilons = generator_funs[d]()\n",
    "                # pad node features for VGRNN\n",
    "                if models[k] == 'VGRNN':\n",
    "                    Xs = pad_xs(Xs)\n",
    "                # compute the loss over all time steps\n",
    "                loss = 0.\n",
    "                state = None\n",
    "                for t in range(len(As)):\n",
    "                    # compute loss\n",
    "                    loss_obj, state = loss_funs[k](model, As[t], Xs[t], deltas[t], Epsilons[t], state=state)\n",
    "                    # compute gradient\n",
    "                    loss_obj.backward()\n",
    "                    # accumulate loss\n",
    "                    loss += loss_obj.item()\n",
    "                # perform an optimizer step\n",
    "                optimizer.step()\n",
    "                # store the current loss value in the learning curve\n",
    "                learning_curves[epoch, r] = loss\n",
    "                # compute a new moving average over the loss\n",
    "                if loss_avg is None:\n",
    "                    loss_avg = loss\n",
    "                else:\n",
    "                    loss_avg = loss_avg * 0.9 + 0.1 * loss\n",
    "                # print every print_step steps\n",
    "                if (epoch + 1) % print_step == 0:\n",
    "                    print('loss avg after %d epochs: %g' % (epoch + 1, loss_avg))\n",
    "                # stop early if the moving average is small\n",
    "                if loss_avg < loss_threshold:\n",
    "                    break\n",
    "            # perform evaluation on new time series\n",
    "            results[r, :] = 0.\n",
    "            T = 0\n",
    "            for j in range(N_test):\n",
    "                # get a random time series from the dataset\n",
    "                As, Xs, deltas, Epsilons = generator_funs[d]()\n",
    "                if models[k] == 'VGRNN':\n",
    "                    Xs = pad_xs(Xs)\n",
    "                state = None\n",
    "                for t in range(len(As)):\n",
    "                    # predict the current time step with the network\n",
    "                    delta, Epsilon, state = pred_funs[k](model, As[t], Xs[t], state=state)\n",
    "                    # assess node edit precision and recall\n",
    "                    results[r, :4] += prec_rec(delta, deltas[t])\n",
    "                    # assess edge edit precision and recall\n",
    "                    results[r, 4:] += prec_rec(Epsilon, Epsilons[t])\n",
    "\n",
    "                T += len(As)\n",
    "            results[r, :] /= T\n",
    "            # store runtime\n",
    "            runtimes[r, k] = time.time() - start_time\n",
    "            np.savetxt(runtimes_file, runtimes, delimiter='\\t', fmt='%g', header='\\t'.join(models), comments='')\n",
    "            # store results\n",
    "            np.savetxt(results_file, results, delimiter='\\t', fmt='%g', header='\\t'.join(eval_criteria), comments='')\n",
    "            # store learning curves\n",
    "            np.savetxt(curves_file, learning_curves, delimiter='\\t', fmt='%g')\n",
    "        # print results\n",
    "        for crit in range(len(eval_criteria)):\n",
    "            print('%s: %g +- %g' % (eval_criteria[crit], np.mean(results[:, crit]), np.std(results[:, crit])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "smoothing_steps = 10\n",
    "plt.figure(figsize = (16, 4 * len(datasets)))\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(datasets))\n",
    "for d in range(len(datasets)):\n",
    "    for k in range(len(models)):\n",
    "        curves_file  = 'results/%s_%s_learning_curves.csv' % (datasets[d], models[k])\n",
    "        learning_curves = np.loadtxt(curves_file, delimiter = '\\t')\n",
    "        acum = np.cumsum(np.nanmean(learning_curves, 1))\n",
    "        axes[d].semilogy((acum[smoothing_steps:] - acum[:-smoothing_steps])/smoothing_steps)\n",
    "    axes[d].set_xlabel('epoch')\n",
    "    axes[d].set_ylabel('loss')\n",
    "    axes[d].set_title(datasets[d])\n",
    "    axes[d].legend(models)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
